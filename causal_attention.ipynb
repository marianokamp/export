{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff10ce5d-2c70-4b1e-8445-bcc839483743",
   "metadata": {},
   "source": [
    "### Causal Attention\n",
    "Simplifications: Single head, no mini-batches, no padding, linear only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43163635-2709-44d7-a0a2-f1d25e354894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.set_printoptions(precision=2, linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2c4dbf-3124-4a90-8c01-e7335f10eab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "V = 100 # Vocab size\n",
    "d = 768 # embedding dims\n",
    "T = 5   # seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b76afb-de34-4574-93d6-61a83752e3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(V, d) # embeddings\n",
    "clf = torch.nn.Linear(d, V)    # classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f10af3-b224-4b0d-8af7-1bf4d47b6e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_proj, k_proj, v_proj = nn.Linear(d, d), nn.Linear(d, d), nn.Linear(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18cdeeed-114a-446a-8995-eef85d976b37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([95, 11, 75, 30, 31]), torch.Size([5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.randint(V, (T, )); tokens, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839f9784-154e-46e7-b4dc-e53145dd7b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = emb(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029115d3-a361-4e3d-ab5e-5ff1b0ca437d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v  = q_proj(x), k_proj(x), v_proj(x); q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e72395-98c5-435f-9346-8a6f4fc179a9",
   "metadata": {},
   "source": [
    "Below: Parallel computation -> resulting attention matrix is $\\mathbb{R} ^{TxT}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7277d4d8-cf49-4ced-8f38-3e76f6dc1033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.82, -0.36, -0.15,  0.76, -0.32],\n",
       "         [ 0.03, -0.23, -0.01,  0.25, -0.73],\n",
       "         [ 0.43,  0.37, -0.27,  0.20, -0.52],\n",
       "         [ 0.19, -0.01,  0.19,  0.06, -0.21],\n",
       "         [-0.04,  0.16, -0.30, -0.12, -0.27]], grad_fn=<DivBackward0>),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_att = q@k.t()/torch.sqrt(torch.tensor(d)); raw_att, raw_att.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d26b77-42f1-4526-a420-4364a0f20de2",
   "metadata": {},
   "source": [
    "Below: Each row defines the scores (=pre-attention) of each column in the target sequence. The score ultimately indicates how much do we take from the input sequence's columns into the output sequence's columns.\n",
    "\n",
    "E.g. The third row means that we take values from the first three elements in the input sequence, but not from the remaining two elements, as we are just preparing the information that we use later to predict the third token in the output sequence; we can't see into the future because of the masking.\n",
    "\n",
    "Btw. the next token prediction is separate from that. We'll see this at the end in the section about [Loss](#Loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756e3cd4-7627-49d2-a7a1-874bdb1e3c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.82,  0.00,  0.00,  0.00,  0.00],\n",
       "         [ 0.03, -0.23,  0.00,  0.00,  0.00],\n",
       "         [ 0.43,  0.37, -0.27,  0.00,  0.00],\n",
       "         [ 0.19, -0.01,  0.19,  0.06,  0.00],\n",
       "         [-0.04,  0.16, -0.30, -0.12, -0.27]], grad_fn=<TrilBackward0>),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_att = torch.tril(raw_att); masked_att, masked_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6713906a-96c9-4982-a3d2-cca74a1261b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.82,  -inf,  -inf,  -inf,  -inf],\n",
       "         [ 0.03, -0.23,  -inf,  -inf,  -inf],\n",
       "         [ 0.43,  0.37, -0.27,  -inf,  -inf],\n",
       "         [ 0.19, -0.01,  0.19,  0.06,  -inf],\n",
       "         [-0.04,  0.16, -0.30, -0.12, -0.27]], grad_fn=<MaskedFillBackward0>),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_att = masked_att.masked_fill_(masked_att == 0., float('-inf')); masked_att, masked_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "122b1668-ae92-452a-bc89-573d5dc02312",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.00, 0.00, 0.00, 0.00, 0.00],\n",
       "         [0.56, 0.44, 0.00, 0.00, 0.00],\n",
       "         [0.41, 0.39, 0.20, 0.00, 0.00],\n",
       "         [0.27, 0.22, 0.27, 0.24, 0.00],\n",
       "         [0.21, 0.26, 0.16, 0.20, 0.17]], grad_fn=<SoftmaxBackward0>),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_att = torch.softmax(masked_att, -1); masked_att, masked_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe1fb15-7404-410e-a7b7-dbc31c2734d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.55,  0.09, -0.22,  ..., -0.33, -0.84,  0.01],\n",
       "         [-0.56, -0.08, -0.21,  ..., -0.18, -0.67,  0.24],\n",
       "         [-0.46,  0.01,  0.05,  ..., -0.25, -0.41,  0.30],\n",
       "         [-0.44,  0.09,  0.06,  ..., -0.24, -0.14,  0.39],\n",
       "         [-0.48, -0.11, -0.08,  ..., -0.06, -0.19,  0.39]], grad_fn=<MmBackward0>),\n",
       " torch.Size([5, 768]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = masked_att @ v; new_v, new_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8e5b1-72b2-400e-9cdf-8443769c71b6",
   "metadata": {},
   "source": [
    "### Interlude: Sanity check against the PyTorch built-in scaled dot product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2029c2a-146e-40b0-b360-37fd3347689c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False],\n",
       "        [ True,  True, False, False, False],\n",
       "        [ True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True, False],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask = torch.tril(torch.ones(T, T)) == 1; attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60edb8c2-1bf7-473d-9979-7e91e3c5c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.55,  0.09, -0.22,  ..., -0.33, -0.84,  0.01],\n",
       "        [-0.56, -0.08, -0.21,  ..., -0.18, -0.67,  0.24],\n",
       "        [-0.46,  0.01,  0.05,  ..., -0.25, -0.41,  0.30],\n",
       "        [-0.44,  0.09,  0.06,  ..., -0.24, -0.14,  0.39],\n",
       "        [-0.48, -0.11, -0.08,  ..., -0.06, -0.19,  0.39]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=attn_mask, is_causal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0684a789-be24-470c-9015-4b12a410c4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(_, new_v, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9837d20e-e102-4101-b283-a7a5627b0953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.55,  0.09, -0.22,  ..., -0.33, -0.84,  0.01],\n",
       "        [-0.56, -0.08, -0.21,  ..., -0.18, -0.67,  0.24],\n",
       "        [-0.46,  0.01,  0.05,  ..., -0.25, -0.41,  0.30],\n",
       "        [-0.44,  0.09,  0.06,  ..., -0.24, -0.14,  0.39],\n",
       "        [-0.48, -0.11, -0.08,  ..., -0.06, -0.19,  0.39]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, is_causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b04476-1ea0-4733-8227-993b9f0f99ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(_, new_v, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4c884-9124-4460-acd2-a559dec74b53",
   "metadata": {},
   "source": [
    "### Loss\n",
    "Predict next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aecef28-a39e-4d4c-870b-501d3cc168a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 768]), Linear(in_features=768, out_features=100, bias=True))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v.shape, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f309f22-cf58-49e3-b72f-0574de5e79e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 66, 81, 43, 87]), torch.Size([5, 100]), torch.Size([5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... some more layers ...\n",
    "logits = clf(new_v); logits.argmax(-1), logits.shape, logits.argmax(-1).shape # The argmax gives us the token indices. CE loss below does this implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2f120f4-e5ca-42c7-baeb-ebee6aa59be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.arange(0, T); targets # dummy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03cdaafb-1fb5-48c3-814b-57887d86dfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.54, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.cross_entropy(logits, targets, ignore_index=-1) # -1 an example for a padding index!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
